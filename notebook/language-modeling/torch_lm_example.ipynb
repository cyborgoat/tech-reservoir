{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:24:02.614525Z",
     "end_time": "2023-04-26T21:24:03.265230Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of ``-inf``, with zeros on ``diag``.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:24:03.267030Z",
     "end_time": "2023-04-26T21:24:03.268541Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape [N]\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:24:04.982204Z",
     "end_time": "2023-04-26T21:24:12.062256Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:24:40.937791Z",
     "end_time": "2023-04-26T21:24:40.939792Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:24:46.402776Z",
     "end_time": "2023-04-26T21:24:46.506871Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:24:51.158963Z",
     "end_time": "2023-04-26T21:24:51.165783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 69.83 | loss  8.21 | ppl  3692.24\n",
      "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 67.93 | loss  6.90 | ppl   989.94\n",
      "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 68.37 | loss  6.45 | ppl   635.24\n",
      "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 68.08 | loss  6.31 | ppl   551.15\n",
      "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 69.28 | loss  6.20 | ppl   492.11\n",
      "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 68.19 | loss  6.16 | ppl   472.75\n",
      "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 68.34 | loss  6.12 | ppl   455.42\n",
      "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 68.18 | loss  6.11 | ppl   452.56\n",
      "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 68.10 | loss  6.03 | ppl   415.02\n",
      "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 68.25 | loss  6.02 | ppl   410.39\n",
      "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 69.21 | loss  5.90 | ppl   364.84\n",
      "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 68.75 | loss  5.98 | ppl   393.82\n",
      "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 68.45 | loss  5.96 | ppl   386.43\n",
      "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 68.94 | loss  5.88 | ppl   359.42\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 209.13s | valid loss  5.80 | valid ppl   331.83\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 68.86 | loss  5.87 | ppl   354.31\n",
      "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 68.70 | loss  5.86 | ppl   350.34\n",
      "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 68.60 | loss  5.68 | ppl   294.39\n",
      "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 68.64 | loss  5.72 | ppl   303.67\n",
      "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 68.49 | loss  5.66 | ppl   288.31\n",
      "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 68.56 | loss  5.69 | ppl   296.51\n",
      "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 69.13 | loss  5.70 | ppl   298.06\n",
      "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 69.04 | loss  5.72 | ppl   305.59\n",
      "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 69.80 | loss  5.66 | ppl   287.64\n",
      "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 68.95 | loss  5.68 | ppl   292.39\n",
      "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 69.43 | loss  5.56 | ppl   259.12\n",
      "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 68.71 | loss  5.66 | ppl   287.37\n",
      "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 68.48 | loss  5.65 | ppl   284.70\n",
      "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 68.67 | loss  5.58 | ppl   266.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 209.92s | valid loss  5.67 | valid ppl   290.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 69.02 | loss  5.62 | ppl   274.52\n",
      "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 68.52 | loss  5.63 | ppl   279.15\n",
      "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 68.43 | loss  5.44 | ppl   229.30\n",
      "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 68.56 | loss  5.49 | ppl   242.25\n",
      "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 68.87 | loss  5.45 | ppl   231.84\n",
      "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 68.61 | loss  5.48 | ppl   240.61\n",
      "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 68.67 | loss  5.50 | ppl   245.08\n",
      "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 68.56 | loss  5.53 | ppl   251.35\n",
      "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 68.75 | loss  5.50 | ppl   243.66\n",
      "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 69.83 | loss  5.50 | ppl   244.10\n",
      "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 69.11 | loss  5.36 | ppl   212.64\n",
      "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 68.86 | loss  5.46 | ppl   235.58\n",
      "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 69.72 | loss  5.48 | ppl   239.67\n",
      "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 68.85 | loss  5.40 | ppl   222.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 210.00s | valid loss  5.58 | valid ppl   266.14\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:24:56.978467Z",
     "end_time": "2023-04-26T21:35:26.180692Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.50 | test ppl   243.66\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-26T21:35:26.181656Z",
     "end_time": "2023-04-26T21:35:35.570737Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
