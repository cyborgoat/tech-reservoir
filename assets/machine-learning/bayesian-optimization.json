{"title": "Beyesian Optimization with Python", "summary": "Beyesian optimization explained in detail with python implementation.", "author": "Junxiao Guo", "date": "2023-02-27", "tags": ["machine-learning", "automl"], "content": "---\ntitle: Beyesian Optimization with Python\nsummary: Beyesian optimization explained in detail with python implementation.\nauthor: Junxiao Guo\ndate: 2023-02-27\ntags:\n  - machine-learning\n  - automl\n---\n\nHyperparameter optimization is a challenging problem of finding an input that results in the minimum or maximum cost of a given objective function.\n\nBayesian Optimization provides a principled technique based on Bayes Theorem to direct a search of a global optimization problem that is efficient and effective. It works by building a probabilistic model of the objective function, called the surrogate function, that is then searched efficiently with an acquisition function before candidate samples are chosen for evaluation on the real objective function.\n\nBayesian Optimization is often used in applied machine learning to tune the hyperparameters of a given well-performing model on a validation dataset.\n\n## What is bayesian optimization\n\nBayesian Optimization is an approach that uses Bayes Theorem to direct the search in order to find the minimum or maximum of an objective function.\n\nIt is an approach that is most useful for objective functions that are complex, noisy, and/or expensive to evaluate.\n\nRecall that Bayes Theorem is an approach for calculating the conditional probability of an event:\n\n$$P(A|B) = \\frac{P(B|A) * P(A)}{P(B)}$$\n\nWe can simplify this calculation by removing the normalizing value of P(B) and describe the conditional probability as a proportional quantity. This is useful as we are not interested in calculating a specific conditional probability, but instead in optimizing a quantity.\n\n$$P(A|B) = P(B|A) * P(A)$$\n\nThe conditional probability that we are calculating is referred to generally as the posterior probability; the reverse conditional probability is sometimes referred to as the likelihood, and the marginal probability is referred to as the prior probability; for example:\n\n$$posterior = likelihood * prior$$\nThis provides a framework that can be used to quantify the beliefs about an unknown objective function given samples from the domain and their evaluation via the objective function.\n\nWe can devise specific samples $(x_1, x_2, \u2026, x_n)$ and evaluate them using the objective function f(xi) that returns the cost or outcome for the sample xi. Samples and their outcome are collected sequentially and define our data D, e.g. $D = {x_i, f(x_i), \u2026 x_n, f(x_n)}$ and is used to define the prior. The likelihood function is defined as the probability of observing the data given the function $P(D | f)$. This likelihood function will change as more observations are collected.\n\n$$P(f|D) = P(D|f) * P(f)$$\nThe posterior represents everything we know about the objective function. It is an approximation of the objective function and can be used to estimate the cost of different candidate samples that we may want to evaluate.\n\nIn this way, the posterior probability is a surrogate objective function.\n\n- **Surrogate Function**: Bayesian approximation of the objective function that can be sampled efficiently.\nThe surrogate function gives us an estimate of the objective function, which can be used to direct future sampling. Sampling involves careful use of the posterior in a function known as the \u201cacquisition\u201d function, e.g. for acquiring more samples. We want to use our belief about the objective function to sample the area of the search space that is most likely to pay off, therefore the acquisition will optimize the conditional probability of locations in the search to generate the next sample.\n\n- **Acquisition Function**: Technique by which the posterior is used to select the next sample from the search space.\nOnce additional samples and their evaluation via the objective function f() have been collected, they are added to data D and the posterior is then updated.\n\nThis process is repeated until the extrema of the objective function is located, a good enough result is located, or resources are exhausted.\n\nThe Bayesian Optimization algorithm can be summarized as follows:\n\n1. Select a Sample by Optimizing the Acquisition Function.\n2. Evaluate the Sample With the Objective Function.\n3. Update the Data and, in turn, the Surrogate Function.\n4. Go To 1.\n\n## Performing Bayesian Optimization\n\nIn this section, we will explore how Bayesian Optimization works by developing an implementation from scratch for a simple one-dimensional test function.\n\nFirst, we will define the test problem, then how to model the mapping of inputs to outputs with a surrogate function. Next, we will see how the surrogate function can be searched efficiently with an acquisition function before tying all of these elements together into the Bayesian Optimization procedure.\n\n```python\nimport numpy as np\nimport math\nfrom matplotlib import pyplot\n```\n\n### Problem definition\n\nWe will use a multimodal problem with five peaks, calculated as:\n\n$$y = x^2 * cos(3 * \\pi * x)^4$$\n\nWhere x is a real value in the range $[0,1]$.\n\nWe will augment this function by adding Gaussian noise with a mean of zero and a standard deviation of 0.1. This will mean that the real evaluation will have a positive or negative random value added to it, making the function challenging to optimize.\n\nThe objective() function below implements this.\n\n```python\n# objective function\ndef objective(x, noise=0.1):\n    noise = np.random.normal(loc=0, scale=noise)\n    return (x**2 * math.cos(3 * math.pi * x)**4.0) + noise\n```\n\nWe can test this function by first defining a grid-based sample of inputs from 0 to 1 with a step size of 0.01 across the domain.\n\n```python\n# grid-based sample of the domain [0,1]\nX = np.arange(0, 1, 0.01)\n```\n\nWe can then evaluate these samples using the target function without any noise to see what the real objective function looks like.\n\n```python\n# sample the domain without noise\ny = [objective(x, 0) for x in X]\n```\n\nWe can then evaluate these same points with noise to see what the objective function will look like when we are optimizing it.\n\n```python\n# sample the domain with noise\nynoise = [objective(x) for x in X]\n```\n\nWe can look at all of the non-noisy objective function values to find the input that resulted in the best score and report it. This will be the optima, in this case, maxima, as we are maximizing the output of the objective function.\n\nWe would not know this in practice, but for out test problem, it is good to know the real best input and output of the function to see if the Bayesian Optimization algorithm can locate it.\n\n```python\n# find best result\nix = np.argmax(y)\nprint('Optima: x=%.3f, y=%.3f' % (X[ix], y[ix]))\n```\n\n    Optima: x=0.990, y=0.963\n\nFinally, we can create a plot, first showing the noisy evaluation as a scatter plot with input on the x-axis and score on the y-axis, then a line plot of the scores without any noise.\n\n```python\n# plot the points with noise\npyplot.scatter(X, ynoise)\n# plot the points without noise\npyplot.plot(X, y)\n# show the plot\npyplot.show()\n```\n\n![png](https://dsm01pap004files.storage.live.com/y4mInhTedeUbNyjbXJ0sZaxsO299h_7sNc7c1hafPiWnRb85aje5EeKCiQCqgqHzHJfo8EgHJ2CDkKKFfWVk3yfptS_0fWYs8kDY-x_HEC3blYRG_Gk23Kd2lVfNEnuxpkMOf0Lw9ZAITS_G802vbv3GMPhNb3kJgubwFvsN872aGgaZJEfX9ZN5EEa0sQzNDgq?width=547&height=413&cropmode=none)\n\n### Surrogate Function\n\nThe surrogate function is a technique used to best approximate the mapping of input examples to an output score.\n\nProbabilistically, it summarizes the conditional probability of an objective function $(f)$, given the available data $(D)$ or $P(f|D)$.\n\nA number of techniques can be used for this, although the most popular is to treat the problem as a regression predictive modeling problem with the data representing the input and the score representing the output to the model. This is often best modeled using a random forest or a Gaussian Process.\n\nA Gaussian Process, or GP, is a model that constructs a joint probability distribution over the variables, assuming a multivariate Gaussian distribution. As such, it is capable of efficient and effective summarization of a large number of functions and smooth transition as more observations are made available to the model.\n\nThis smooth structure and smooth transition to new functions based on data are desirable properties as we sample the domain, and the multivariate Gaussian basis to the model means that an estimate from the model will be a mean of a distribution with a standard deviation; that will be helpful later in the acquisition function.\n\nAs such, using a GP regression model is often preferred.\n\nWe can fit a GP regression model using the GaussianProcessRegressor scikit-learn implementation from a sample of inputs $(X)$ and noisy evaluations from the objective function $(y)$.\n\nFirst, the model must be defined. An important aspect in defining the GP model is the kernel. This controls the shape of the function at specific points based on distance measures between actual data observations. Many different kernel functions can be used, and some may offer better performance for specific datasets.\n\nBy default, a Radial Basis Function, or RBF, is used that can work well.\n\nOnce defined, the model can be fit on the training dataset directly by calling the fit() function.\n\nThe defined model can be fit again at any time with updated data concatenated to the existing data by another call to fit().\n\nThe model will estimate the cost for one or more samples provided to it.\n\nThe model is used by calling the predict() function. The result for a given sample will be a mean of the distribution at that point. We can also get the standard deviation of the distribution at that point in the function by specifying the argument return_std=True; for example:\n\nThis function can result in warnings if the distribution is thin at a given point we are interested in sampling.\n\nTherefore, we can silence all of the warnings when making a prediction. The surrogate() function below takes the fit model and one or more samples and returns the mean and standard deviation estimated costs whilst not printing any warnings.\n\n```python\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom scipy.stats import norm\nfrom warnings import catch_warnings\nfrom warnings import simplefilter\n# surrogate or approximation for the objective function\ndef surrogate(model, X):\n # catch any warning generated when making a prediction\n with catch_warnings():\n  # ignore generated warnings\n  simplefilter(\"ignore\")\n  return model.predict(X, return_std=True)\n```\n\nWe can call this function any time to estimate the cost of one or more samples, such as when we want to optimize the acquisition function in the next section.\n\nFor now, it is interesting to see what the surrogate function looks like across the domain after it is trained on a random sample.\n\nWe can achieve this by first fitting the GP model on a random sample of 100 data points and their real objective function values with noise. We can then plot a scatter plot of these points. Next, we can perform a grid-based sample across the input domain and estimate the cost at each point using the surrogate function and plot the result as a line.\n\nWe would expect the surrogate function to have a crude approximation of the true non-noisy objective function.\n\nThe plot() function below creates this plot, given the random data sample of the real noisy objective function and the fit model.\n\n```python\n# plot real observations vs surrogate function\ndef plot(X, y, model):\n # scatter plot of inputs and real objective function\n pyplot.scatter(X, y)\n # line plot of surrogate function across domain\n Xsamples = np.asarray(np.arange(0, 1, 0.001))\n Xsamples = Xsamples.reshape(len(Xsamples), 1)\n ysamples, _ = surrogate(model, Xsamples)\n pyplot.plot(Xsamples, ysamples)\n # show the plot\n pyplot.show()\n```\n\n```python\n# sample the domain sparsely with noise\nX = np.random.random(100)\ny = np.asarray([objective(x) for x in X])\n# reshape into rows and cols\nX = X.reshape(len(X), 1)\ny = y.reshape(len(y), 1)\n# define the model\nmodel = GaussianProcessRegressor()\n# fit the model\nmodel.fit(X, y)\n# plot the surrogate function\nplot(X, y, model)\n```\n\n![png](https://dsm01pap004files.storage.live.com/y4mQJ0vfVUOQqMZIicbxQqdhO_D6URlgeFjIwq0eE3jCC6AJOOpjHxIuSKUPPTtQHYu1tpMl_-OhzY4TBi2td5PlV5wj-2ElvHnYeBBiqhrzNtUKGaOHOYgckJboYhKNI-JXbfCDSpuUonqF94q9oOI1QeJyg72npjjzgYWAJcFGDYyySqOFunW3w8Hf8v-P8bT?width=559&height=413&cropmode=none)\n\nRunning the example first draws the random sample, evaluates it with the noisy objective function, then fits the GP model.\n\nThe data sample and a grid of points across the domain evaluated via the surrogate function are then plotted as dots and a line respectively.\n\nNote: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n\nIn this case, as we expected, the plot resembles a crude version of the underlying non-noisy objective function, importantly with a peak around 0.9 where we know the true maxima is located.\n\n### Acquisition Function\n\nThe surrogate function is used to test a range of candidate samples in the domain.\n\nFrom these results, one or more candidates can be selected and evaluated with the real, and in normal practice, computationally expensive cost function.\n\nThis involves two pieces: the search strategy used to navigate the domain in response to the surrogate function and the acquisition function that is used to interpret and score the response from the surrogate function.\n\nA simple search strategy, such as a random sample or grid-based sample, can be used, although it is more common to use a local search strategy, such as the popular BFGS algorithm. In this case, we will use a random search or random sample of the domain in order to keep the example simple.\n\nThis involves first drawing a random sample of candidate samples from the domain, evaluating them with the acquisition function, then maximizing the acquisition function or choosing the candidate sample that gives the best score. The opt_acquisition() function below implements this.\n\n```python\n# optimize the acquisition function\ndef opt_acquisition(X, y, model):\n # random search, generate random samples\n Xsamples = np.random.random(100)\n Xsamples = Xsamples.reshape(len(Xsamples), 1)\n # calculate the acquisition function for each sample\n scores = acquisition(X, Xsamples, model)\n # locate the index of the largest scores\n ix = np.argmax(scores)\n return Xsamples[ix, 0]\n```\n\nThe acquisition function is responsible for scoring or estimating the likelihood that a given candidate sample (input) is worth evaluating with the real objective function.\n\nWe could just use the surrogate score directly. Alternately, given that we have chosen a Gaussian Process model as the surrogate function, we can use the probabilistic information from this model in the acquisition function to calculate the probability that a given sample is worth evaluating.\n\nThere are many different types of probabilistic acquisition functions that can be used, each providing a different trade-off for how exploitative (greedy) and explorative they are.\n\nThree common examples include:\n\nProbability of Improvement (PI).\nExpected Improvement (EI).\nLower Confidence Bound (LCB).\nThe Probability of Improvement method is the simplest, whereas the Expected Improvement method is the most commonly used.\n\nIn this case, we will use the simpler Probability of Improvement method, which is calculated as the normal cumulative probability of the normalized expected improvement, calculated as follows:\n\n$$PI = cdf\\left(\\frac{\\mu \u2013 best_\\mu}{stdev}\\right)$$\nWhere PI is the probability of improvement, cdf() is the normal cumulative distribution function, mu is the mean of the surrogate function for a given sample x, stdev is the standard deviation of the surrogate function for a given sample x, and best_mu is the mean of the surrogate function for the best sample found so far.\n\nWe can add a very small number to the standard deviation to avoid a divide by zero error.\n\nThe acquisition() function below implements this given the current training dataset of input samples, an array of new candidate samples, and the fit GP model.\n\n```python\n# probability of improvement acquisition function\ndef acquisition(X, Xsamples, model):\n    # calculate the best surrogate score found so far\n    yhat, _ = surrogate(model, X)\n    best = max(yhat)\n    # calculate mean and stdev via surrogate function\n    mu, std = surrogate(model, Xsamples)\n    mu = mu[0]\n    # calculate the probability of improvement\n    probs = norm.cdf((mu - best) / (std+1E-9))\n    return probs\n```\n\n### Complete Bayesian Optimization Algorithm\n\nWe can tie all of this together into the Bayesian Optimization algorithm.\n\nThe main algorithm involves cycles of selecting candidate samples, evaluating them with the objective function, then updating the GP model.\n\n```python\n# perform the optimization process\nfor i in range(100):\n    # select the next point to sample\n    x = opt_acquisition(X, y, model)\n    # sample the point\n    actual = objective(x)\n    # summarize the finding for our own reporting\n    est, _ = surrogate(model, [[x]])\n    print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n    # add the data to the dataset\n    X = np.vstack((X, [[x]]))\n    y = np.vstack((y, [[actual]]))\n    # update the model\n    model.fit(X, y)\n```\n\n    >x=0.730, f()=0.184289, actual=0.121\n    >x=0.111, f()=-0.027583, actual=-0.074\n    >x=0.552, f()=0.143937, actual=0.110\n    >x=0.018, f()=-0.027990, actual=-0.092\n    >x=0.183, f()=0.037242, actual=-0.161\n    >x=0.314, f()=0.044528, actual=0.119\n    >x=0.501, f()=0.092083, actual=0.225\n    ......\n    >x=0.031, f()=-0.041620, actual=0.012\n\n```python\n# example of bayesian optimization for a 1d function from scratch\nfrom math import sin\nfrom math import pi\nfrom numpy import arange\nfrom numpy import vstack\nfrom numpy import argmax\nfrom numpy import asarray\nfrom numpy.random import normal\nfrom numpy.random import random\nfrom scipy.stats import norm\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom warnings import catch_warnings\nfrom warnings import simplefilter\nfrom matplotlib import pyplot\n\n# objective function\ndef objective(x, noise=0.1):\n    noise = normal(loc=0, scale=noise)\n    return (x**2 * sin(5 * pi * x)**6.0) + noise\n\n# surrogate or approximation for the objective function\ndef surrogate(model, X):\n    # catch any warning generated when making a prediction\n    with catch_warnings():\n        # ignore generated warnings\n        simplefilter(\"ignore\")\n        return model.predict(X, return_std=True)\n\n# probability of improvement acquisition function\ndef acquisition(X, Xsamples, model):\n    # calculate the best surrogate score found so far\n    yhat, _ = surrogate(model, X)\n    best = max(yhat)\n    # calculate mean and stdev via surrogate function\n    mu, std = surrogate(model, Xsamples)\n    mu = mu[0]\n    # calculate the probability of improvement\n    probs = norm.cdf((mu - best) / (std+1E-9))\n    return probs\n\n# optimize the acquisition function\ndef opt_acquisition(X, y, model):\n    # random search, generate random samples\n    Xsamples = random(100)\n    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n    # calculate the acquisition function for each sample\n    scores = acquisition(X, Xsamples, model)\n    # locate the index of the largest scores\n    ix = argmax(scores)\n    return Xsamples[ix, 0]\n\n# plot real observations vs surrogate function\ndef plot(X, y, model):\n    # scatter plot of inputs and real objective function\n    pyplot.scatter(X, y)\n    # line plot of surrogate function across domain\n    Xsamples = asarray(arange(0, 1, 0.001))\n    Xsamples = Xsamples.reshape(len(Xsamples), 1)\n    ysamples, _ = surrogate(model, Xsamples)\n    pyplot.plot(Xsamples, ysamples)\n    # show the plot\n    pyplot.show()\n\n# sample the domain sparsely with noise\nX = random(100)\ny = asarray([objective(x) for x in X])\n# reshape into rows and cols\nX = X.reshape(len(X), 1)\ny = y.reshape(len(y), 1)\n# define the model\nmodel = GaussianProcessRegressor()\n# fit the model\nmodel.fit(X, y)\n# plot before hand\nplot(X, y, model)\n# perform the optimization process\nfor i in range(100):\n    # select the next point to sample\n    x = opt_acquisition(X, y, model)\n    # sample the point\n    actual = objective(x)\n    # summarize the finding\n    est, _ = surrogate(model, [[x]])\n    print('>x=%.3f, f()=%3f, actual=%.3f' % (x, est, actual))\n    # add the data to the dataset\n    X = vstack((X, [[x]]))\n    y = vstack((y, [[actual]]))\n    # update the model\n    model.fit(X, y)\n\n# plot all samples and the final surrogate function\nplot(X, y, model)\n# best result\nix = argmax(y)\nprint('Best Result: x=%.3f, y=%.3f' % (X[ix], y[ix]))\n```\n\n![png](https://dsm01pap004files.storage.live.com/y4m8ahGYviDQ901UeEgThVseAhF9Xlo7M9Z5n41GdPAkRzcNkkkwa-2UtuTIeLK3179sj7Pqn8FdNF1QV6_o0MLClWzRnfDa5gG9Z0NAS4LRAgyE_7gMkvWlHeMtRnEFWIRxr0gYav0rZRc5ri9UxpiXercaYGth6SmLnHnVjiQaVigPh6cRenr6cpW5ScURLGg?width=559&height=413&cropmode=none)\n\n    >x=0.102, f()=0.060782, actual=0.292\n    >x=0.873, f()=0.413320, actual=0.536\n    >x=0.843, f()=0.320122, actual=-0.048\n    >x=0.891, f()=0.448285, actual=0.706\n    >x=0.616, f()=0.048923, actual=-0.051\n    >x=0.908, f()=0.495629, actual=0.960\n    ......\n    >x=0.842, f()=0.298019, actual=0.010\n    >x=0.032, f()=0.029685, actual=0.024\n    >x=0.167, f()=0.058235, actual=0.048\n    >x=0.558, f()=0.125632, actual=0.080\n\n![png](https://dsm01pap004files.storage.live.com/y4ma1jfCa3KlXDBUj70DlKbLU0XsflExx5ueX0qX5wM4ZmwRqOWfyCMrS0c8G57gOvD5ofEwFOWw6XQaef10dgaPL_CA8h57iTz4ZXjk2APmSCakbD1bbbT9VBD9wKJd79wkSYBqBYp1er2qht8LmjfwH6ppn8GXJIBfimPdF3KRWF1kxnXpKW0_aLoGBk6xhf2?width=559&height=413&cropmode=none)\n\n    Best Result: x=0.908, y=0.960\n\n## Hyperparameter Tuning With Bayesian Optimization\n\nIt can be a useful exercise to implement Bayesian Optimization to learn how it works.\n\nIn practice, when using Bayesian Optimization on a project, it is a good idea to use a standard implementation provided in an open-source library. This is to both avoid bugs and to leverage a wider range of configuration options and speed improvements.\n\nTwo popular libraries for Bayesian Optimization include Scikit-Optimize and HyperOpt. In machine learning, these libraries are often used to tune the hyperparameters of algorithms.\n\nHyperparameter tuning is a good fit for Bayesian Optimization because the evaluation function is computationally expensive (e.g. training models for each set of hyperparameters) and noisy (e.g. noise in training data and stochastic learning algorithms).\n\nIn this section, we will take a brief look at how to use the Scikit-Optimize library to optimize the hyperparameters of a k-nearest neighbor classifier for a simple test classification problem. This will provide a useful template that you can use on your own projects.\n\nThe Scikit-Optimize project is designed to provide access to Bayesian Optimization for applications that use SciPy and NumPy, or applications that use scikit-learn machine learning algorithms.\n\n```python\n!pip install scikit-optimize\n```\n\n    Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n    Requirement already satisfied: scikit-optimize in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (0.9.0)\n    Requirement already satisfied: joblib>=0.11 in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (from scikit-optimize) (1.1.1)\n    Requirement already satisfied: numpy>=1.13.3 in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (from scikit-optimize) (1.23.5)\n    Requirement already satisfied: pyaml>=16.9 in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (from scikit-optimize) (21.10.1)\n    Requirement already satisfied: scikit-learn>=0.20.0 in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (from scikit-optimize) (1.2.1)\n    Requirement already satisfied: scipy>=0.19.1 in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (from scikit-optimize) (1.10.0)\n    Requirement already satisfied: PyYAML in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n    Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/junxiaoguo/opt/anaconda3/envs/ml/lib/python3.10/site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n\n```python\n# example of bayesian optimization with scikit-optimize\nfrom numpy import mean\nfrom sklearn.datasets import make_blobs\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom skopt.space import Integer\nfrom skopt.utils import use_named_args\nfrom skopt import gp_minimize\n\n# generate 2d classification dataset\nX, y = make_blobs(n_samples=500, centers=3, n_features=2)\n# define the model\nmodel = KNeighborsClassifier()\n# define the space of hyperparameters to search\nsearch_space = [Integer(1, 5, name='n_neighbors'), Integer(1, 2, name='p')]\n\n# define the function used to evaluate a given configuration\n@use_named_args(search_space)\ndef evaluate_model(**params):\n # something\n model.set_params(**params)\n # calculate 5-fold cross validation\n result = cross_val_score(model, X, y, cv=5, n_jobs=-1, scoring='accuracy')\n # calculate the mean of the scores\n estimate = mean(result)\n return 1.0 - estimate\n\n# perform optimization\nresult = gp_minimize(evaluate_model, search_space)\n# summarizing finding:\nprint('Best Accuracy: %.3f' % (1.0 - result.fun))\nprint('Best Parameters: n_neighbors=%d, p=%d' % (result.x[0], result.x[1]))\n```\n\n    Best Accuracy: 0.976\n    Best Parameters: n_neighbors=5, p=2\n\nRunning the example executes the hyperparameter tuning using Bayesian Optimization.\n\n```python\n\n```\n"}